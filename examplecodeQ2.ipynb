{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d858f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fuzzywuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas numpy matplotlib statsmodels\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd19a081",
   "metadata": {},
   "source": [
    "***1.Import dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46771aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\DATA for CLASS\\NZDATA-FORCALCULATINGAMIHUD.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149ca6b",
   "metadata": {},
   "source": [
    "***2.Data Cleaning***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['Date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['RET_INDEX'] = pd.to_numeric(df['TOT RETURN IND'], errors='coerce')\n",
    "df['PRC'] = pd.to_numeric(df['UNADJUSTED PRICE'], errors='coerce')\n",
    "df['VOL'] = pd.to_numeric(df['TURNOVER BY VOLUME'], errors='coerce')\n",
    "\n",
    "#datastream VOL was divided 1000, therefore we should multuple 1000\n",
    "df['VOL']=df['VOL']*1000\n",
    "\n",
    "#keep stocks that daily Volume>20000, to ensure we exclude all the stocks will extreme low liqudity\n",
    "df = df[df['VOL'] > 20000]\n",
    "df = df[df['PRC'] > 1]\n",
    "\n",
    "#df.head(5)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fea1447",
   "metadata": {},
   "source": [
    "***3.covert TOT RETURN IND*** TO SIMPLE REUTRN\n",
    "* Since the data is from data stream, total return index (TOT RETURN IND) is the return index inlcduing dividends.\n",
    "* To convert simple return, ***((TOT RETURN IND )t  - (TOT RETURN IND )t-1)-1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RET'] = df['TOT RETURN IND'].pct_change()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80568b60",
   "metadata": {},
   "source": [
    "***4.Create Amihud Illiquidity for each stock each day***\n",
    "Amihud illiquidity= ((absolute value of Return)/(vol*PRC))*10^6\n",
    "\n",
    "\n",
    "high amihud value --->illiquidity\n",
    "low amihud value---->liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269805be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DOLLAR_VOL'] = df['VOL'] * df['PRC'].abs()\n",
    "df['amihud_daily'] = df['RET'].abs() / df['DOLLAR_VOL']*(10**6)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b766448",
   "metadata": {},
   "source": [
    "***5.Groupby and obtain monthly Amihud Illiquidity for each stock***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dac000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['date'].dt.to_period('M')\n",
    "\n",
    "\n",
    "df = df[df['DOLLAR_VOL'] > 0]###only keep dollar volume rows   abs_ret_div_dollarvol\n",
    "\n",
    "# calculate Amihud illiquidity group by month and stock name\n",
    "amihud_illiq = df.groupby(['Stock_Name', 'month'])['amihud_daily'].mean().reset_index()\n",
    "amihud_illiq.rename(columns={'amihud_daily': 'Amihud_Illiquidity'}, inplace=True)\n",
    "#amihud_illiq['Amihud_Transform']=amihud_illiq['Amihud_Illiquidity']\n",
    "amihud_illiq.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a86e772",
   "metadata": {},
   "source": [
    "***6.Create quintiles for Each year based on Amihud Illiquidity***\n",
    "for each year, we divided sotck for 5 quintiles, top 20% stocks month with lowest Amihud Illiquidity at Q1, \n",
    "20% stock month with second lowest Amihud Illiquidity at Q2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "amihud_illiq['illiquidity_quintile'] = amihud_illiq.groupby('month')['Amihud_Illiquidity']\\\n",
    "    .transform(lambda x: pd.qcut(x, 5, labels=['Q1', 'Q2', 'Q3', 'Q4', 'Q5']))\n",
    "##lamba x is a temporary def, x here is all Amihud illuidity at a month. qcut divide the input x into 5 quintiles.\n",
    "\n",
    "amihud_illiq.head(5)\n",
    "#merged_df_Amihud_RET.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0928b6",
   "metadata": {},
   "source": [
    "***7.Calculate each quintile's average Amihud illiquity***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e438d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "#winsorize\n",
    "amihud_values = amihud_illiq['Amihud_Illiquidity'].values\n",
    "amihud_winsorized = winsorize(amihud_values, limits=[0.01, 0.01])\n",
    "amihud_illiq['Amihud_Illiquidity_winsorized'] = amihud_winsorized\n",
    "\n",
    "#calculate each quintile's average Amihud_Illiquidity\n",
    "avg_illiquidity_by_quintile = amihud_illiq.groupby('illiquidity_quintile')['Amihud_Illiquidity_winsorized'].mean()\n",
    "\n",
    "print(avg_illiquidity_by_quintile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e1cfe",
   "metadata": {},
   "source": [
    "****7.Import Each firm's monthly return****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly, show current dataframe\n",
    "amihud_illiq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file_path =r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\NZDATA-MonthData.csv'\n",
    "df_MRET = pd.read_csv(file_path)\n",
    "\n",
    "# Parse date and set month\n",
    "df_MRET['Date'] = pd.to_datetime(df_MRET['Date'], dayfirst=True)\n",
    "df_MRET['month'] = df_MRET['Date'].dt.to_period('M')\n",
    "\n",
    "# Convert TOT RETURN IND to numeric (cleaning step)\n",
    "df_MRET['TOT RETURN IND'] = pd.to_numeric(df_MRET['TOT RETURN IND'], errors='coerce')\n",
    "df_MRET['MARKET CAPITALIZATION'] = pd.to_numeric(df_MRET['MARKET CAPITALIZATION'], errors='coerce')\n",
    "\n",
    "# Drop rows where TOT RETURN IND is missing\n",
    "df_MRET = df_MRET.dropna(subset=['TOT RETURN IND'])\n",
    "\n",
    "# Sort and compute returns\n",
    "df_MRET = df_MRET.sort_values(['Stock_Name', 'Date'])\n",
    "\n",
    "df_MRET['monthly_return'] = (\n",
    "    df_MRET\n",
    "    .groupby('Stock_Name')['TOT RETURN IND']\n",
    "    .pct_change()\n",
    ")\n",
    "\n",
    "df_MRET['monthly_log_return'] = np.log(1 + df_MRET['monthly_return'])\n",
    "\n",
    "df_MRET.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc84eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MRET.to_csv(r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\test\\mret222.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4da98a",
   "metadata": {},
   "source": [
    "***8.merge Monthly_log_return to Amihud and Quintile, groupby month and permno***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9685190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "\n",
    "\n",
    "###we are going to use fuzzy matching in this step. we are trying to merge two files, but the key is not 100% same.\n",
    "##for example, stock name '2 cheap cars' and '2 cheap cars group'\n",
    "##therefore, Fuzzy match on company names\n",
    "\n",
    "# ensure 'month' is datetime\n",
    "if pd.api.types.is_period_dtype(df_MRET['month']):\n",
    "    df_MRET['month'] = df_MRET['month'].dt.to_timestamp()\n",
    "else:\n",
    "    df_MRET['month'] = pd.to_datetime(df_MRET['month'])\n",
    "\n",
    "if pd.api.types.is_period_dtype(amihud_illiq['month']):\n",
    "    amihud_illiq['month'] = amihud_illiq['month'].dt.to_timestamp()\n",
    "else:\n",
    "    amihud_illiq['month'] = pd.to_datetime(amihud_illiq['month'])\n",
    "\n",
    "# align date\n",
    "df_MRET['month'] = df_MRET['month'] + MonthEnd(0)\n",
    "amihud_illiq['month'] = amihud_illiq['month'] + MonthEnd(0)\n",
    "\n",
    "\n",
    "# Step 2: Fuzzy mapping\n",
    "stock_names_MRET = df_MRET['Stock_Name'].unique()\n",
    "stock_names_ill = amihud_illiq['Stock_Name'].unique()\n",
    "\n",
    "name_map = {}\n",
    "for name in stock_names_ill:\n",
    "    match, score = process.extractOne(name, stock_names_MRET)\n",
    "    if score >= 90:\n",
    "        name_map[name] = match\n",
    "\n",
    "amihud_illiq['Stock_Name_matched'] = amihud_illiq['Stock_Name'].map(name_map)\n",
    "\n",
    "# Step 3: Merge\n",
    "merged_df_Amihud_MRET = pd.merge(\n",
    "    df_MRET,\n",
    "    amihud_illiq,\n",
    "    left_on=['month', 'Stock_Name'],\n",
    "    right_on=['month', 'Stock_Name_matched'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "merged_df_Amihud_MRET['month'] = merged_df_Amihud_MRET['Date'].dt.to_period('M')\n",
    "\n",
    "print(merged_df_Amihud_MRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8dd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_Amihud_MRET.to_csv(r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\test\\mret.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd98b3",
   "metadata": {},
   "source": [
    "***9.import ff3 and CAPM factors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89323ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path =r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\NZDATA-AlphaFactors.xlsx'\n",
    "df_factor = pd.read_excel(file_path)\n",
    "df_factor['date'] = pd.to_datetime(df_factor['Date'])\n",
    "df_factor['month'] = df_factor['date'].dt.to_period('M')\n",
    "df_factor.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1634ca",
   "metadata": {},
   "source": [
    "***10.merge month ff3 and CAPM factors Amihud and Quintile, groupby month***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58428bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df_Amihud_MRET_ff3 = pd.merge(df_factor, merged_df_Amihud_MRET, on=[ 'month'], how='inner')\n",
    "\n",
    "#merged_df_Amihud_MRET_ff3.head(5)\n",
    "print(merged_df_Amihud_MRET_ff3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e8c92",
   "metadata": {},
   "source": [
    "***11.This is our data set for final analysis, we can save this to csv***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_Amihud_MRET_ff3.to_csv(r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\test\\merged_df_Amihud_MRET_ff3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42683f34",
   "metadata": {},
   "source": [
    "***12. calculate monthly equal-weighted return***\n",
    "we already get the monthly return for each stock, so we can just calculate equal-weighted return for each month\n",
    "Equal-weighted return is the average return of a portfolio where each stock is assigned the same weight, regardless of its market capitalization.\n",
    "\n",
    "equal weighted return is for the market, not the single stocks。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c715160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path =r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\test\\merged_df_Amihud_MRET_ff3.csv'\n",
    "df_all = pd.read_csv(file_path)\n",
    "\n",
    "# each month equal-weighted return\n",
    "equal_weighted_returns = (\n",
    "    df_all.groupby(\"month\")[\"monthly_return\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"monthly_return\": \"equal_weighted_return\"})\n",
    ")\n",
    "\n",
    "\n",
    "print(equal_weighted_returns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe1b943",
   "metadata": {},
   "source": [
    "***13. summary statistics for monthly equal-weighted return***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be2798",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_weighted_returns.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07330a1b",
   "metadata": {},
   "source": [
    "***14. eqch quintile equal weighted return***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_weighted_returns_q = (\n",
    "    df_all.groupby(\"illiquidity_quintile\")[\"monthly_return\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"monthly_return\": \"equal_weighted_return_q\"})\n",
    ")\n",
    "print(equal_weighted_returns_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bfcd7a",
   "metadata": {},
   "source": [
    "***15.calculate CAPM alpha for each stock each month***\n",
    "R_it - R_ft = α_i + β_i (R_mt - R_ft) + ε_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ---------- 1. generate「each month × each quintile」equal weight return ----------\n",
    "port_rets = (\n",
    "    df_all\n",
    "    .groupby([\"month\", \"illiquidity_quintile\"])[\"monthly_return\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"monthly_return\": \"port_return\"})\n",
    ")\n",
    "\n",
    "# ---------- 2. merge to FF3 factors ----------\n",
    "# 提取当月的 Mkt-RF 和 RF，每月一行\n",
    "factors = df_all[[\"month\", \"Mkt-RF\", \"RF\"]].drop_duplicates()\n",
    "factors[[\"Mkt-RF\", \"RF\"]] = factors[[\"Mkt-RF\", \"RF\"]] / 100  # 转换成小数形式\n",
    "\n",
    "# 合并因子数据\n",
    "port_rets = port_rets.merge(factors, on=\"month\", how=\"left\")\n",
    "\n",
    "# ---------- 3. compute contemporaneous excess return ----------\n",
    "port_rets[\"excess_return\"] = port_rets[\"port_return\"] - port_rets[\"RF\"]\n",
    "\n",
    "# ---------- 4. generate t+1 excess return ----------\n",
    "# 按照每个组合排序时间序列，shift(-1) 得到 t+1 的收益\n",
    "port_rets = port_rets.sort_values([\"illiquidity_quintile\", \"month\"])\n",
    "port_rets[\"excess_return_t1\"] = (\n",
    "    port_rets.groupby(\"illiquidity_quintile\")[\"excess_return\"]\n",
    "    .shift(-1)\n",
    ")\n",
    "\n",
    "# ---------- 5. regression: using t illiquidity to predict t+1 excess return ----------\n",
    "results = []\n",
    "\n",
    "for q in port_rets[\"illiquidity_quintile\"].unique():\n",
    "    sub = port_rets[port_rets[\"illiquidity_quintile\"] == q].sort_values(\"month\")\n",
    "\n",
    "    # 删除最后一个月（因为shift后变成NaN）\n",
    "    sub = sub.dropna(subset=[\"excess_return_t1\"])\n",
    "\n",
    "    X = sm.add_constant(sub[\"Mkt-RF\"])  # 控制市场因子\n",
    "    y = sub[\"excess_return_t1\"]         # 被解释变量是 t+1 超额收益\n",
    "\n",
    "    res = sm.OLS(y, X).fit()\n",
    "\n",
    "    results.append({\n",
    "        \"quintile\"     : q,\n",
    "        \"alpha\"        : res.params[\"const\"],\n",
    "        \"alpha_tstat\"  : res.tvalues[\"const\"],\n",
    "        \"beta\"         : res.params[\"Mkt-RF\"],\n",
    "        \"n_obs\"        : len(sub)\n",
    "    })\n",
    "\n",
    "# ---------- 6. output summary ----------\n",
    "alpha_df = pd.DataFrame(results).sort_values(\"quintile\")\n",
    "print(alpha_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c971412",
   "metadata": {},
   "source": [
    "***15.CAPM difference between bottom and top quintile***\n",
    "\n",
    "we are testing, if the excess return most liquidity portfolio  - the least liquidity portfolio significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#generate「each month × each quintile」ew return\n",
    "port_rets = (\n",
    "    df_all\n",
    "    .groupby([\"month\", \"illiquidity_quintile\"])[\"monthly_return\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"monthly_return\": \"port_return\"})\n",
    ")\n",
    "\n",
    "#  convert to wide table \n",
    "wide = port_rets.pivot(index=\"month\",\n",
    "                       columns=\"illiquidity_quintile\",\n",
    "                       values=\"port_return\")\n",
    "\n",
    "wide[\"long_short\"] = wide[\"Q5\"] - wide[\"Q1\"]      \n",
    "\n",
    "# 3. merge ff3 factors \n",
    "factors = df_all[[\"month\", \"Mkt-RF\", \"RF\"]].drop_duplicates()\n",
    "ls_df   = wide.reset_index().merge(factors, on=\"month\", how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "ls_df[\"excess_ls\"] = ls_df[\"long_short\"] - ls_df[\"RF\"]\n",
    "\n",
    "# only keep non-missing\n",
    "reg_df = ls_df[[\"excess_ls\", \"Mkt-RF\"]].dropna()\n",
    "\n",
    "# 3. construct x, y\n",
    "X = sm.add_constant(reg_df[\"Mkt-RF\"])\n",
    "y = reg_df[\"excess_ls\"]\n",
    "#R_it - R_ft = α_i + β_i (R_mt - R_ft) + ε_t\n",
    "\n",
    "# 4. \n",
    "model = sm.OLS(y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 12})\n",
    "\n",
    "print(model.summary())         # 现在就不会报错了\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1055af",
   "metadata": {},
   "source": [
    "***16.calculate ff3 alpha for each stock each month***\n",
    "(R_it - R_ft) = α_i + β_i (R_mt - R_ft) + s_i · SMB_t + h_i · HML_t + ε_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0622cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "port_rets = (\n",
    "    df_all\n",
    "    .groupby([\"month\", \"illiquidity_quintile\"])[\"monthly_return\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"monthly_return\": \"port_return\"})\n",
    ")\n",
    "\n",
    "#merge ff3 factors\n",
    "factors = df_all[[\"month\", \"Mkt-RF\", \"RF\", \"smb\", \"hml\"]].drop_duplicates()\n",
    "factors[[\"Mkt-RF\", \"RF\", \"smb\", \"hml\"]] = factors[[\"Mkt-RF\", \"RF\", \"smb\", \"hml\"]] / 100  # 转成小数\n",
    "\n",
    "port_rets = port_rets.merge(factors, on=\"month\", how=\"left\")\n",
    "\n",
    "# calculate excess return\n",
    "port_rets[\"excess_return\"] = port_rets[\"port_return\"] - port_rets[\"RF\"]\n",
    "\n",
    "# t+1 port terurn\n",
    "port_rets = port_rets.sort_values([\"illiquidity_quintile\", \"month\"])\n",
    "port_rets[\"excess_return_t1\"] = (\n",
    "    port_rets.groupby(\"illiquidity_quintile\")[\"excess_return\"]\n",
    "    .shift(-1)\n",
    ")\n",
    "\n",
    "# ff3 regression\n",
    "results = []\n",
    "\n",
    "for q in port_rets[\"illiquidity_quintile\"].unique():\n",
    "    sub = port_rets[port_rets[\"illiquidity_quintile\"] == q].sort_values(\"month\")\n",
    "\n",
    "    sub = sub.dropna(subset=[\"excess_return_t1\"])\n",
    "\n",
    "    X = sub[[\"Mkt-RF\", \"smb\", \"hml\"]]\n",
    "    X = sm.add_constant(X)\n",
    "    y = sub[\"excess_return_t1\"]\n",
    "\n",
    "    res = sm.OLS(y, X).fit()\n",
    "\n",
    "    results.append({\n",
    "        \"quintile\"    : q,\n",
    "        \"ff3_alpha\"   : res.params[\"const\"],  \n",
    "        \"alpha_tstat\" : res.tvalues[\"const\"],\n",
    "        \"beta_mkt\"    : res.params[\"Mkt-RF\"],\n",
    "        \"beta_smb\"    : res.params[\"smb\"],\n",
    "        \"beta_hml\"    : res.params[\"hml\"],\n",
    "        \"n_obs\"       : len(sub)\n",
    "    })\n",
    "\n",
    "# output\n",
    "ff3_alpha_df = pd.DataFrame(results).sort_values(\"quintile\")\n",
    "print(ff3_alpha_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50048f0f",
   "metadata": {},
   "source": [
    "***17.difference between bottom and top quintile**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e06502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ---------- 1. 每月 × 每个quintile 的组合收益 ----------\n",
    "port_rets = (\n",
    "    df_all\n",
    "    .groupby([\"month\", \"illiquidity_quintile\"])[\"monthly_return\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"monthly_return\": \"port_return\"})\n",
    ")\n",
    "\n",
    "# ---------- 2. 转成宽表，构造 Q5-Q1 long-short 组合 ----------\n",
    "wide = port_rets.pivot(index=\"month\",\n",
    "                       columns=\"illiquidity_quintile\",\n",
    "                       values=\"port_return\")\n",
    "\n",
    "wide[\"long_short\"] = wide[\"Q5\"] - wide[\"Q1\"]\n",
    "\n",
    "# ---------- 3. 合并 FF3 因子 ----------\n",
    "factors = df_all[[\"month\", \"Mkt-RF\", \"RF\", \"smb\", \"hml\"]].drop_duplicates()\n",
    "factors[[\"Mkt-RF\", \"RF\", \"smb\", \"hml\"]] = factors[[\"Mkt-RF\", \"RF\", \"smb\", \"hml\"]] / 100  # 转换为小数\n",
    "\n",
    "ls_df = wide.reset_index().merge(factors, on=\"month\", how=\"left\")\n",
    "\n",
    "# ---------- 4. 计算超额收益 ----------\n",
    "ls_df[\"excess_ls\"] = ls_df[\"long_short\"] - ls_df[\"RF\"]\n",
    "\n",
    "# ---------- 5. 构造回归样本 ----------\n",
    "reg_df = ls_df[[\"excess_ls\", \"Mkt-RF\", \"smb\", \"hml\"]].dropna()\n",
    "\n",
    "X = sm.add_constant(reg_df[[\"Mkt-RF\", \"smb\", \"hml\"]])\n",
    "y = reg_df[\"excess_ls\"]\n",
    "\n",
    "# ---------- 6. FF3 回归 + HAC 标准误 ----------\n",
    "model = sm.OLS(y, X).fit(cov_type=\"HAC\", cov_kwds={\"maxlags\": 12})\n",
    "\n",
    "# ---------- 7. 输出结果 ----------\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec59d96",
   "metadata": {},
   "source": [
    "###Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ea0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- 1. Load & clean basic columns ----\n",
    "path = r'C:\\Users\\yumi7517\\OneDrive - University of Otago\\Desktop\\FINC503\\A1 material-python\\RAW NZ-DATA FOR A1\\final\\DATA for CLASS\\test\\merged_df_Amihud_MRET_ff3.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "\n",
    "df['month'] = pd.to_datetime(df['month']) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "# convert market return to decimal\n",
    "if df['Mkt-RF'].abs().max() > 1:\n",
    "    df[['Mkt-RF', 'RF']] = df[['Mkt-RF', 'RF']] / 100\n",
    "\n",
    "df['Mkt'] = df['Mkt-RF'] + df['RF']\n",
    "\n",
    "# ---- 2. Equal-weighted return by quintile ----\n",
    "port_mean = (\n",
    "    df.groupby(['month', 'illiquidity_quintile'])['monthly_return']\n",
    "      .mean()\n",
    "      .unstack()\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "#  Q1、Q5、Q5-Q1 and Market\n",
    "q1 = port_mean.get('Q1')\n",
    "q5 = port_mean.get('Q5')\n",
    "long_short = q5 - q1\n",
    "mkt = df.groupby('month')['Mkt'].mean().reindex(port_mean.index)\n",
    "\n",
    "# Convert to cumulative log return \n",
    "def to_cumulative_log_return(series):\n",
    "    return np.log1p(series).cumsum()  # log(1 + r)\n",
    "\n",
    "cum_q1 = to_cumulative_log_return(q1)\n",
    "cum_q5 = to_cumulative_log_return(q5)\n",
    "cum_ls = to_cumulative_log_return(long_short)\n",
    "cum_mkt = to_cumulative_log_return(mkt)\n",
    "\n",
    "# Plot cumulative returns \n",
    "plt.figure(figsize=(11, 6))\n",
    "plt.plot(cum_q5.index, cum_q5, label='Q5 (Most Illiquid)')\n",
    "plt.plot(cum_q1.index, cum_q1, label='Q1 (Most Liquid)')\n",
    "plt.plot(cum_ls.index, cum_ls, label='Long‑Short (Q5 – Q1)')\n",
    "plt.plot(cum_mkt.index, cum_mkt, label='Market')\n",
    "\n",
    "plt.title('Cumulative Log Returns: Liquidity Quintiles vs. Market')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Cumulative Log Return')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
